{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the appropriate number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.cluster as clustering\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_asos = pd.read_csv(\"/share/share/combined_asos_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_asos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_lls = combined_asos.groupby(\"station\")[[\"lat\", \"lon\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stations_lls['lon'], stations_lls['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clustering = clustering.KMeans(n_clusters=5).fit(stations_lls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "num_clusters = np.arange(1, 21,1)\n",
    "sses = np.empty(num_clusters.shape)\n",
    "for k in num_clusters:\n",
    "    curr_clusters = clustering.KMeans(n_clusters=k, max_iter=1000, n_init='auto').fit(stations_lls)\n",
    "    sses[k-1] = curr_clusters.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(num_clusters, sses)\n",
    "plt.xticks(np.arange(1,21, 2))\n",
    "plt.grid(True)\n",
    "plt.xlim(1,20)\n",
    "plt.ylim(0,500000)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Sum of Squared Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mean_vals = combined_asos.groupby('station')[['lat','lon','tmpf','dwpf', 'sknt']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mean_vals = station_mean_vals.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mean_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "num_clusters = np.arange(1, 21,1)\n",
    "sses = np.empty(num_clusters.shape)\n",
    "for k in num_clusters:\n",
    "    curr_clusters = clustering.KMeans(n_clusters=k, max_iter=1000, n_init='auto').fit(station_mean_vals[['tmpf','dwpf', 'sknt']])\n",
    "    sses[k-1] = curr_clusters.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(num_clusters, sses)\n",
    "plt.xticks(np.arange(1,21, 2))\n",
    "plt.grid(True)\n",
    "plt.xlim(1,20)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Sum of Squared Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_clusters = clustering.KMeans(n_clusters=5, max_iter=1000, n_init='auto').fit(station_mean_vals[['tmpf','dwpf', 'sknt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(station_mean_vals['lon'], station_mean_vals['lat'], c=curr_clusters.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Method \n",
    "# adapted from sklearn documentation\n",
    "\n",
    "\n",
    "num_clusters = np.arange(2, 11,2)\n",
    "scores = np.empty(num_clusters.shape)\n",
    "for iter, k in enumerate(num_clusters):\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    curr_clusters = clustering.KMeans(n_clusters=k, max_iter=1000, n_init='auto').fit(station_mean_vals[['tmpf','dwpf', 'sknt']])\n",
    "    sil_score = silhouette_score(station_mean_vals[['tmpf','dwpf', 'sknt']], curr_clusters.labels_)\n",
    "    sample_vals = silhouette_samples(station_mean_vals[['tmpf','dwpf', 'sknt']], curr_clusters.labels_)\n",
    "    y_lower=10\n",
    "    for i in range(k):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_vals[curr_clusters.labels_ == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / k)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=sil_score, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aes690st-sp24-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
